# opencv_task2

以下是我在完成任务中的一些记录。

9.19
----------------------------------------------------------------------------
已完成：
1.转化为灰度图。  
2.转化为 HSV 图片。  
3.均值滤波。  
4.高斯滤波。  
5.利用hsv方法来提取图像中的红色颜色区域。  
6.一定程度上完成了图像中红色外轮廓以及其bounding box的寻找（不太确定）。  
7.计算轮廓的面积（这里使用的是opencv中自带的contourArea函数）。  
8.图像绘制：文字选取为“hello，opencv”，同时绘制了圆形与正方形，将第一次用hsv方法提取出来的图像中的红色颜色区域的外轮廓勾勒了出来。并且绘制了红色的bounding box。  
9.图像处理部分：图像旋转35度以及裁剪为原图像左上角的四分之一。

目前问题集中在图形学处理部分。第一次代码大部分为提示词下通义大模型的帮助下完成，初步了解了传统图像处理的部分操作以及opencv中的函数与变量等。代码仍待修改与完善。

刚刚过了二十分钟，我对代码进行了一定的完善如下：  
1.增大了hsv图中红色的判定范围，是的判定清况更加符合实际。  
2.修改了源代码中部分进行形态学操作的代码，因为没有符合要求，随后利用hsv图像顺  
利地提取了图中的高亮部分，并通过灰度化图像与二值化图像来展示。  
大概这就是9.19号完成的所有任务了。  

9.20
-------------------------------------------------------------------------------
今天目前完成了第二次任务一中的所有任务，在完成第一天剩余任务的同时，还对第一天的代码进行了结构上的优化以及目录上的优化。具体如下：  
1.完成了上一次没有完成的形态学操作。  
2.将以前使用的WaitAndShow函数替换为了新定义的saveImageToOutputFolder函数，解决了main函数输出在build文件夹中的问题。  
3.将图片名字作了修改，并将其保存到了output文件夹中，目录结构可能会更加清晰，易于理解吧。  
4.删除了因昨天部分功能失败而产生的冗余代码。  

现在准备开始第二次培训的任务task2。

刚刚不太了解装甲板是什么，后面在网上搜集了以下，得到了装甲板的大概定义是什么：  
“装甲板”指的是安装在机器人身上的特定识别区域，这些灯条或图案在图像中表现为明亮的、颜色特定的区域，它们通常成对出现，形成一个矩形或类矩形的结构；作为目标识别点，供敌方机器人或己方视觉系统识别和定位，通过识别装甲板的位置，可以计算出机器人的位置、姿态。  
那么基本思路可以为：想要找出装甲板区域，可以先找出其中的灯条区域。在进行一些滤波操作后，先用hsv图分离 v通道再加上二值化，得到图片中的亮色区域面积，再通过矩形长和宽的限制来得到装甲板的灯条区域。现在看看能不能实现。  

经过调试与尝试，我发现一开始的思路是存在问题的。通过反复尝试，我重新确定了基本思路如下：  
先将图像转化为灰度图，之后进行均值滤波(在给定图片的处理中，似乎高斯滤波的效果没有均值滤波好。)；接下来对滤波后的灰度图片进行二值化，再对其进行形态学处理包括先腐蚀后膨胀（即开操作）；接下来便是对处理后的图片进行判定。  

因为led灯条是矩形形状，因此我一开始使用矩形框出白色部分，然后用框出矩形的长宽比来对我的判定进行约束，比如判定长宽比是否在3.0和4.0之间，但由于有一些其他区域的不规则亮度图形在矩形框出后也具有符合条件的长宽比，因此我决定增强我的约束条件：因为白色部分面积与矩形框出的面积是存在不重合部分的，这便反映了矩形框的精度，对于led灯条这种比较类似的规范的矩形，重合部分面积与矩形面积之比一定是相对大一些的，因此在约束矩形长宽比的同时，我也对重合面积与矩形面积比进行了约束，最后得到了较
为理想的结果。

到目前为止，第二次培训的任务基本结束了。
-------------------------------------------------------------------------------
